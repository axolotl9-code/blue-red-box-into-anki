{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SfIhggRKviVC",
    "outputId": "d29cd2fc-27b9-46bb-d25b-20e2182fd36c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: genanki in /Users/joyungeon/Library/Python/3.13/lib/python/site-packages (0.13.1)\n",
      "Requirement already satisfied: pandas in /Users/joyungeon/Library/Python/3.13/lib/python/site-packages (2.3.3)\n",
      "Requirement already satisfied: cached-property in /Users/joyungeon/Library/Python/3.13/lib/python/site-packages (from genanki) (2.0.1)\n",
      "Requirement already satisfied: frozendict in /Users/joyungeon/Library/Python/3.13/lib/python/site-packages (from genanki) (2.4.6)\n",
      "Requirement already satisfied: chevron in /Users/joyungeon/Library/Python/3.13/lib/python/site-packages (from genanki) (0.14.0)\n",
      "Requirement already satisfied: pyyaml in /Users/joyungeon/Library/Python/3.13/lib/python/site-packages (from genanki) (6.0.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/joyungeon/Library/Python/3.13/lib/python/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/joyungeon/Library/Python/3.13/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/joyungeon/Library/Python/3.13/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/joyungeon/Library/Python/3.13/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/joyungeon/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/joyungeon/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install genanki pandas\n",
    "import genanki\n",
    "import hashlib\n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iu19dHQp8VD2"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def boxing(image_input):\n",
    "  \"\"\"\n",
    "  Applies bounding boxes to red regions in an image.\n",
    "\n",
    "  Args:\n",
    "    image_input: Either a file path (str) or a PIL Image object.\n",
    "\n",
    "  Returns:\n",
    "    A PIL Image object with bounding boxes drawn.\n",
    "  \"\"\"\n",
    "  if isinstance(image_input, str):\n",
    "      # If input is a file path, read the image using cv2\n",
    "      img = cv2.imread(image_input)\n",
    "      if img is None:\n",
    "          raise FileNotFoundError(f\"Image not found at {image_input}\")\n",
    "      # Convert OpenCV BGR to RGB for PIL compatibility later\n",
    "      img_rgb_cv2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "      img_pil = Image.fromarray(img_rgb_cv2)\n",
    "  elif isinstance(image_input, Image.Image):\n",
    "      # If input is a PIL Image, convert it to OpenCV format (BGR)\n",
    "      img_pil = image_input.convert(\"RGB\") # Ensure RGB format for consistency\n",
    "      img_rgb_cv2 = np.array(img_pil)\n",
    "      img = cv2.cvtColor(img_rgb_cv2, cv2.COLOR_RGB2BGR)\n",
    "  else:\n",
    "      raise TypeError(\"Input must be a file path (str) or a PIL Image object\")\n",
    "\n",
    "\n",
    "  # Convert to HSV to isolate red regions (use the BGR image for HSV conversion)\n",
    "  hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "  # Define red color range and create mask\n",
    "  lower_red1 = np.array([0, 70, 50])\n",
    "  upper_red1 = np.array([10, 255, 255])\n",
    "  lower_red2 = np.array([170, 70, 50])\n",
    "  upper_red2 = np.array([180, 255, 255])\n",
    "  mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "  mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "  mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "  # Find contours of red regions\n",
    "  contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  # Extract bounding boxes\n",
    "  boxes = []\n",
    "  for cnt in contours:\n",
    "      bbox_x, bbox_y, bbox_w, bbox_h = cv2.boundingRect(cnt)\n",
    "      # Ignore tiny dots or noise\n",
    "      if bbox_w > 30 and bbox_h > 5:\n",
    "          boxes.append((bbox_x, bbox_y, bbox_x + bbox_w, bbox_y + bbox_h))\n",
    "\n",
    "  # Sort boxes by top-to-bottom, then left-to-right\n",
    "  boxes = sorted(boxes, key=lambda b: (b[1], b[0]))\n",
    "\n",
    "  # Draw rectangles on the PIL image object\n",
    "  draw = ImageDraw.Draw(img_pil)\n",
    "  for x1, y1, x2, y2 in boxes:\n",
    "      # Convert coordinates to integers\n",
    "      x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "      draw.rectangle([(x1, y1), (x2, y2)], outline=\"darkred\", fill=\"darkred\", width=2)\n",
    "\n",
    "  return img_pil # Return the PIL image object\n",
    "\n",
    "# Call the function and display the result (example usage - can be removed or commented out)\n",
    "# Example with file path:\n",
    "# image_path_example = '/path/to/your/image.jpg'\n",
    "# if os.path.exists(image_path_example):\n",
    "#   processed_example = boxing(image_path_example)\n",
    "#   display(processed_example)\n",
    "# else:\n",
    "#   print(f\"Example image not found at {image_path_example}\")\n",
    "\n",
    "# Example with PIL Image object (requires a PIL image object to be created first)\n",
    "# try:\n",
    "#     pil_image_example = Image.open('/path/to/another/image.png')\n",
    "#     processed_pil_example = boxing(pil_image_example)\n",
    "#     display(processed_pil_example)\n",
    "# except FileNotFoundError:\n",
    "#     print(\"Another example image not found.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error processing PIL example: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_blue_boxes(image_input):\n",
    "    \"\"\"\n",
    "    Finds blue regions in an image and returns their bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        image_input: Either a file path (str) or a PIL Image object.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples (x1, y1, x2, y2) representing the coordinates of blue boxes,\n",
    "        sorted from top to bottom.\n",
    "    \"\"\"\n",
    "    if isinstance(image_input, str):\n",
    "        # If input is a file path, read the image using cv2\n",
    "        img = cv2.imread(image_input)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Image not found at {image_input}\")\n",
    "    elif isinstance(image_input, Image.Image):\n",
    "        # If input is a PIL Image, convert it to OpenCV format (BGR)\n",
    "        img_pil = image_input.convert(\"RGB\")  # Ensure RGB format for consistency\n",
    "        img = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)\n",
    "    else:\n",
    "        raise TypeError(\"Input must be a file path (str) or a PIL Image object\")\n",
    "\n",
    "    # Convert to HSV to isolate blue regions\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define blue color range and create mask\n",
    "    # Blue typically has a hue value around 120 in HSV\n",
    "    lower_blue = np.array([100, 50, 50])\n",
    "    upper_blue = np.array([140, 255, 255])\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # Find contours of blue regions\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Extract bounding boxes\n",
    "    boxes = []\n",
    "    for cnt in contours:\n",
    "        bbox_x, bbox_y, bbox_w, bbox_h = cv2.boundingRect(cnt)\n",
    "        # Ignore tiny dots or noise (adjust these thresholds as needed)\n",
    "        if bbox_w > 30 and bbox_h > 5:\n",
    "            boxes.append((bbox_x, bbox_y, bbox_x + bbox_w, bbox_y + bbox_h))\n",
    "\n",
    "    # Sort boxes by top-to-bottom\n",
    "    boxes = sorted(boxes, key=lambda b: b[1])\n",
    "\n",
    "    return boxes\n",
    "\n",
    "def crop_image_to_box(image, box):\n",
    "    \"\"\"\n",
    "    Crops an image to the specified box coordinates.\n",
    "\n",
    "    Args:\n",
    "        image: PIL Image object\n",
    "        box: Tuple of (x1, y1, x2, y2) coordinates\n",
    "\n",
    "    Returns:\n",
    "        A PIL Image object containing just the cropped region\n",
    "    \"\"\"\n",
    "    return image.crop(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77ed021e",
    "outputId": "915fa6ad-01c3-46d6-b649-c9c686944702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory found: .\n",
      "Subdirectories found:\n",
      "- 완성된 안키 카드들\n",
      "- processed_images_output\n",
      "- 과목들\n",
      "- .git\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the expected base directory\n",
    "base_dir = \".\"\n",
    "\n",
    "# Check if the base directory exists\n",
    "if os.path.exists(base_dir):\n",
    "    print(f\"Base directory found: {base_dir}\")\n",
    "    # List subdirectories to further verify\n",
    "    subdirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    if subdirs:\n",
    "        print(\"Subdirectories found:\")\n",
    "        for subdir in subdirs:\n",
    "            print(f\"- {subdir}\")\n",
    "    else:\n",
    "        print(\"No subdirectories found in the base directory.\")\n",
    "else:\n",
    "    print(f\"Base directory not found: {base_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93ecd89e",
    "outputId": "4b2a7ca2-686c-4763-c4e1-7125fff39fa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of image files found: 0\n",
      "Image file paths:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the base directory path\n",
    "\n",
    "\n",
    "# Create an empty list to store the paths of image files\n",
    "image_files = []\n",
    "\n",
    "# Traverse the base directory and its subdirectories\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        # Check if the file is a regular file and has an image extension\n",
    "        if os.path.isfile(os.path.join(root, file)) and file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # Construct the full path to the image file\n",
    "            image_path = os.path.join(root, file)\n",
    "            # Append the full image path to the list\n",
    "            image_files.append(image_path)\n",
    "\n",
    "# Print the total number of image files found and the list of image file paths\n",
    "print(f\"Total number of image files found: {len(image_files)}\")\n",
    "print(\"Image file paths:\")\n",
    "for image_file in image_files:\n",
    "    print(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-tsTR4rBji4",
    "outputId": "38bb178f-5fb5-4b67-85b6-1562688565e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a list to store the specified information for each image\n",
    "image_data_list = []\n",
    "\n",
    "# Define the name of the directory to exclude from subjects\n",
    "anki_cards_dir_name = \"완성된 안키 카드들\"\n",
    "\n",
    "# Get the list of immediate subdirectories in the base directory (these are the person names)\n",
    "try:\n",
    "    person_dirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "except FileNotFoundError:\n",
    "    print(f\"Base directory not found: {base_dir}\")\n",
    "    person_dirs = []\n",
    "\n",
    "\n",
    "for person_name in person_dirs:\n",
    "    person_root = os.path.join(base_dir, person_name)\n",
    "\n",
    "    # Get the list of immediate subdirectories within the person's directory (these are the subject names)\n",
    "    try:\n",
    "        subject_dirs = [d for d in os.listdir(person_root) if os.path.isdir(os.path.join(person_root, d))]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Person directory not found: {person_root}\")\n",
    "        continue\n",
    "\n",
    "    for subject_name in subject_dirs:\n",
    "        # Explicitly skip the Anki cards directory\n",
    "        if subject_name == anki_cards_dir_name:\n",
    "            continue\n",
    "\n",
    "        subject_root = os.path.join(person_root, subject_name)\n",
    "\n",
    "        # Look for image files directly in the subject directory\n",
    "        try:\n",
    "            for file in os.listdir(subject_root):\n",
    "                image_path = os.path.join(subject_root, file)\n",
    "                # Check if the file is a regular file and has an image extension\n",
    "                if os.path.isfile(image_path) and file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    try:\n",
    "                        # Open the original image using PIL\n",
    "                        original_image = Image.open(image_path)\n",
    "\n",
    "                        # Get the original filename\n",
    "                        original_filename = os.path.basename(image_path)\n",
    "\n",
    "                        # Append the data as a list [person_name, subject_name, original_filename, original_image]\n",
    "                        image_data_list.append([person_name, subject_name, original_filename, original_image])\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing image {image_path}: {e}\")\n",
    "        except FileNotFoundError:\n",
    "             print(f\"Subject directory not found: {subject_root}\")\n",
    "             continue\n",
    "\n",
    "# Display the resulting list structure (optional, for verification)\n",
    "print(image_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIx-PLELnEYt",
    "outputId": "fd9bbb79-bff1-4129-d6fb-df6994419025"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in image_data_list resized to 1280 pixels width.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Define the target width\n",
    "target_width = 1280\n",
    "\n",
    "# Iterate through the image_data_list\n",
    "for item in image_data_list:\n",
    "    # Get the original image (which is at index 3)\n",
    "    original_image = item[3]\n",
    "\n",
    "    # Get the original dimensions\n",
    "    original_width, original_height = original_image.size\n",
    "\n",
    "    # Calculate the new height while maintaining the aspect ratio\n",
    "    # Ensure target_width and original_width are not zero to avoid division by zero\n",
    "    if original_width > 0:\n",
    "        aspect_ratio = original_height / original_width\n",
    "        new_height = int(target_width * aspect_ratio)\n",
    "    else:\n",
    "        # Handle cases where original_width is zero (shouldn't happen with valid images, but as a safeguard)\n",
    "        new_height = original_height # Keep original height if width is zero\n",
    "        print(f\"Warning: Original image width is zero for item: {item[2]}\")\n",
    "\n",
    "\n",
    "    # Resize the image\n",
    "    try:\n",
    "        resized_image = original_image.resize((target_width, new_height), Image.Resampling.LANCZOS) # Use LANCZOS for good quality\n",
    "        # Replace the original image in the list with the resized image\n",
    "        item[3] = resized_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error resizing image {item[2]}: {e}\")\n",
    "\n",
    "print(f\"Images in image_data_list resized to {target_width} pixels width.\")\n",
    "\n",
    "# Optional: Display the first few resized images to verify\n",
    "# if len(image_data_list) > 0:\n",
    "#     print(\"First few resized images:\")\n",
    "#     for i in range(min(3, len(image_data_list))):\n",
    "#         display(image_data_list[i][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3V3KFLM4Ei6i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image processing completed.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Iterate through the image_data_list\n",
    "for item in image_data_list:\n",
    "    # Get the original image (which is at index 3)\n",
    "    original_image = item[3]\n",
    "\n",
    "    try:\n",
    "        # First, check for blue boxes\n",
    "        blue_boxes = find_blue_boxes(original_image)\n",
    "        \n",
    "        if blue_boxes:\n",
    "            # If blue boxes exist, process each blue box separately\n",
    "            print(f\"Found {len(blue_boxes)} blue boxes in image: {item[2]} (from {item[0]}/{item[1]})\")\n",
    "            \n",
    "            # Create a list to store processed regions for this image\n",
    "            processed_regions = []\n",
    "            \n",
    "            for i, blue_box in enumerate(blue_boxes):\n",
    "                # Crop the image to the blue box region\n",
    "                cropped_image = crop_image_to_box(original_image, blue_box)\n",
    "                \n",
    "                # Apply the boxing function to find red regions in the cropped area\n",
    "                processed_cropped = boxing(cropped_image)\n",
    "                \n",
    "                # Store the processed region along with its index\n",
    "                processed_regions.append((i, cropped_image, processed_cropped))\n",
    "                \n",
    "                # Display the cropped regions\n",
    "                print(f\"  Blue box region {i+1}:\")\n",
    "                print(\"    Original cropped region:\")\n",
    "                display(cropped_image)\n",
    "                print(\"    Processed cropped region:\")\n",
    "                display(processed_cropped)\n",
    "                \n",
    "            # Add the processed regions to the item\n",
    "            item.append(processed_regions)\n",
    "            \n",
    "        else:\n",
    "            # If no blue boxes, process the entire image as before\n",
    "            processed_image = boxing(original_image)\n",
    "            \n",
    "            # Display the original and processed images\n",
    "            print(f\"Processing full image: {item[2]} (from {item[0]}/{item[1]})\")\n",
    "            print(\"  Original Image:\")\n",
    "            display(original_image)\n",
    "            print(\"  Processed Image:\")\n",
    "            display(processed_image)\n",
    "            \n",
    "            # Add the processed image to the item (with None as index to indicate full image)\n",
    "            item.append([(None, original_image, processed_image)])\n",
    "        \n",
    "        print(\"-\" * 20)  # Separator for clarity\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {item[2]} (from {item[0]}/{item[1]}): {e}\")\n",
    "\n",
    "print(\"Image processing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ouCPrViEj8da",
    "outputId": "a9948ecd-b745-451c-9e5d-3e712cef50fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file and images saved to: ./processed_images_output\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where the CSV and image files will be saved\n",
    "output_dir = \"./processed_images_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the path for the output CSV file\n",
    "csv_output_path = os.path.join(output_dir, \"image_pairs.csv\")\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open(csv_output_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "\n",
    "    # Iterate through the image_data_list\n",
    "    # Each item now contains [person_name, subject_name, original_filename, original_image, processed_regions]\n",
    "    for item in image_data_list:\n",
    "        original_filename = item[2]\n",
    "        processed_regions = item[4]  # List of (index, original_crop, processed_crop)\n",
    "\n",
    "        # Process each region (either cropped from blue box or full image)\n",
    "        for idx, orig_crop, proc_crop in processed_regions:\n",
    "            # Generate filenames for this region\n",
    "            name, ext = os.path.splitext(original_filename)\n",
    "            if idx is not None:\n",
    "                # For blue box regions, add region number\n",
    "                region_suffix = f\"_region{idx+1}\"\n",
    "            else:\n",
    "                # For full images (no blue boxes), don't add region number\n",
    "                region_suffix = \"\"\n",
    "\n",
    "            processed_img_save_name = f\"{name}{region_suffix}-1_processed{ext}\"\n",
    "            original_img_save_name = f\"{name}{region_suffix}-1_original{ext}\"\n",
    "\n",
    "            # Define full paths for saving the images\n",
    "            processed_img_save_path = os.path.join(output_dir, processed_img_save_name)\n",
    "            original_img_save_path = os.path.join(output_dir, original_img_save_name)\n",
    "\n",
    "            # Save the processed and original images\n",
    "            proc_crop.save(processed_img_save_path)\n",
    "            orig_crop.save(original_img_save_path)\n",
    "\n",
    "            # Write a row to the CSV with the image filenames\n",
    "            csv_writer.writerow([processed_img_save_name, original_img_save_name])\n",
    "\n",
    "print(f\"CSV file and images saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a6b104a"
   },
   "source": [
    "## Group data by person and subject\n",
    "\n",
    "### Subtask:\n",
    "Process the `image_data_list` to group the image data by person and then by subject.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baa8491f"
   },
   "source": [
    "**Reasoning**:\n",
    "Initialize an empty dictionary and iterate through the image_data_list to group the data by person and then by subject as described in the instructions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dc3aaf8e"
   },
   "outputs": [],
   "source": [
    "grouped_data = {}\n",
    "\n",
    "for item in image_data_list:\n",
    "    person_name = item[0]\n",
    "    subject_name = item[1]\n",
    "\n",
    "    if person_name not in grouped_data:\n",
    "        grouped_data[person_name] = {}\n",
    "\n",
    "    if subject_name not in grouped_data[person_name]:\n",
    "        grouped_data[person_name][subject_name] = []\n",
    "\n",
    "    grouped_data[person_name][subject_name].append(item)\n",
    "\n",
    "# Optional: Display the grouped_data structure to verify\n",
    "# print(grouped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efd798df"
   },
   "source": [
    "## Iterate through grouped data\n",
    "\n",
    "### Subtask:\n",
    "Loop through the grouped data, processing each subject for each person.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4a76b6d"
   },
   "source": [
    "**Reasoning**:\n",
    "Iterate through the grouped data by person and subject to prepare for Anki deck creation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3751bf69"
   },
   "outputs": [],
   "source": [
    "for person_name, subjects_data in grouped_data.items():\n",
    "    print(f\"Processing person: {person_name}\")\n",
    "    for subject_name, image_items in subjects_data.items():\n",
    "        print(f\"  Processing subject: {subject_name}\")\n",
    "        # The image_items list contains all the data for this person and subject\n",
    "        # print(f\"    Found {len(image_items)} images for this subject.\") # Optional: verify count\n",
    "        # The next steps will involve creating an Anki deck using genanki for these image_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3333e40"
   },
   "source": [
    "## Create anki deck and model\n",
    "\n",
    "### Subtask:\n",
    "For each subject, create a `genanki.Deck` and `genanki.Model` with appropriate fields and templates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a272de2"
   },
   "source": [
    "**Reasoning**:\n",
    "Define the Anki model and deck structure for each subject.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dc4cca6e",
    "outputId": "1775baf7-b638-4f64-db4c-cd302bb9981b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anki models and decks defined. Ready to create notes and packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Base model ID\n",
    "base_model_id = 1234567890\n",
    "\n",
    "# Store decks to process later\n",
    "decks_to_create = []\n",
    "\n",
    "# Iterate through the grouped data\n",
    "for person_name, subjects_data in grouped_data.items():\n",
    "    print(f\"Processing person: {person_name}\")\n",
    "    for subject_name, image_items in subjects_data.items():\n",
    "        print(f\"  Processing subject: {subject_name}\")\n",
    "\n",
    "        # Generate a unique model ID based on the subject name\n",
    "        # Using hashlib to ensure uniqueness per subject\n",
    "        subject_hash = int(hashlib.sha256(subject_name.encode('utf-8')).hexdigest(), 16) % (10**9) # Limit hash to 9 digits\n",
    "        model_id = base_model_id + subject_hash\n",
    "\n",
    "        # Define the Anki Model\n",
    "        my_model = genanki.Model(\n",
    "            model_id,\n",
    "            'Simple Image Card',\n",
    "            fields=[\n",
    "                {'name': 'Processed Image'},\n",
    "                {'name': 'Original Image'},\n",
    "                {'name': 'Original Filename'}, # Field for the original filename\n",
    "            ],\n",
    "            templates=[\n",
    "                {\n",
    "                    'name': 'Card 1',\n",
    "                    'qfmt': '{{Processed Image}}',  # Front of the card shows the processed image\n",
    "                    'afmt': '{{FrontSide}}<hr id=\"answer\">{{Original Image}}<br>Original Filename: {{Original Filename}}', # Back shows original image and filename\n",
    "                },\n",
    "            ])\n",
    "\n",
    "        # Create the Anki Deck for the subject\n",
    "        my_deck = genanki.Deck(\n",
    "            abs(hash(subject_name)), # Use a hash of the subject name for deck ID\n",
    "            '자동으로 만든 덱::자동으로 만든 '+subject_name)\n",
    "\n",
    "        # Store the deck and the associated image items\n",
    "        decks_to_create.append((my_deck, my_model, image_items, person_name, subject_name))\n",
    "\n",
    "print(\"Anki models and decks defined. Ready to create notes and packages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "982a47cf",
    "outputId": "fb876895-9fef-4310-cb57-979e1cdab373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All notes created and added to their respective decks.\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the stored decks and image items\n",
    "for my_deck, my_model, image_items, person_name, subject_name in decks_to_create:\n",
    "    print(f\"Creating notes for deck: {subject_name} ({person_name})\")\n",
    "\n",
    "    # Add notes to the deck\n",
    "    for item in image_data_list:\n",
    "        original_filename = item[2]\n",
    "        processed_regions = item[4]  # List of (index, original_crop, processed_crop)\n",
    "        \n",
    "        # If there are blue boxes, we'll combine all regions into one note\n",
    "        if processed_regions and processed_regions[0][0] is not None:\n",
    "            # Generate HTML for all processed regions\n",
    "            processed_html = []\n",
    "            original_html = []\n",
    "            \n",
    "            for idx, orig_crop, proc_crop in processed_regions:\n",
    "                name, ext = os.path.splitext(original_filename)\n",
    "                region_suffix = f\"_region{idx+1}\"\n",
    "                \n",
    "                processed_img_filename = f\"{name}{region_suffix}-1_processed{ext}\"\n",
    "                original_img_filename = f\"{name}{region_suffix}-1_original{ext}\"\n",
    "                \n",
    "                processed_html.append(f'<img src=\"{processed_img_filename}\">')\n",
    "                original_html.append(f'<img src=\"{original_img_filename}\">')\n",
    "            \n",
    "            # Create one note with all regions\n",
    "            my_note = genanki.Note(\n",
    "                model=my_model,\n",
    "                fields=[\n",
    "                    '<br>'.join(processed_html),  # All processed regions stacked vertically\n",
    "                    '<br>'.join(original_html),   # All original regions stacked vertically\n",
    "                    original_filename             # Original filename without region suffix\n",
    "                ])\n",
    "            \n",
    "            my_deck.add_note(my_note)\n",
    "            \n",
    "        else:\n",
    "            # For images without blue boxes, create a single note as before\n",
    "            processed_img_filename = f\"{original_filename.rsplit('.', 1)[0]}-1_processed.{original_filename.rsplit('.', 1)[1]}\"\n",
    "            original_img_filename = f\"{original_filename.rsplit('.', 1)[0]}-1_original.{original_filename.rsplit('.', 1)[1]}\"\n",
    "            \n",
    "            my_note = genanki.Note(\n",
    "                model=my_model,\n",
    "                fields=[\n",
    "                    f'<img src=\"{processed_img_filename}\">',\n",
    "                    f'<img src=\"{original_img_filename}\">',\n",
    "                    original_filename\n",
    "                ])\n",
    "            \n",
    "            my_deck.add_note(my_note)\n",
    "\n",
    "    print(f\"Finished creating notes for deck: {subject_name} ({person_name})\")\n",
    "\n",
    "print(\"All notes created and added to their respective decks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d95beea"
   },
   "source": [
    "**Reasoning**:\n",
    "Package each deck into an .apkg file, including the associated media files (processed and original images).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41974c6e",
    "outputId": "86a7d3ab-ae4d-4d4c-caa1-cc28e075d926"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Anki packages created (with naming adjustments for existing files).\n"
     ]
    }
   ],
   "source": [
    "# Define the base directory where the decks will be saved\n",
    "anki_output_dir = os.path.join(base_dir, \"완성된 안키 카드들\")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(anki_output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through the stored decks and image items\n",
    "for my_deck, my_model, image_items, person_name, subject_name in decks_to_create:\n",
    "    # Define the base output filename for the Anki package (.apkg)\n",
    "    base_apkg_filename = f\"완성된 {subject_name}.apkg\"\n",
    "    apkg_output_path = os.path.join(anki_output_dir, base_apkg_filename)\n",
    "\n",
    "    # Check if the file already exists and modify the filename if necessary\n",
    "    counter = 1\n",
    "    while os.path.exists(apkg_output_path):\n",
    "        name, ext = os.path.splitext(base_apkg_filename)\n",
    "        apkg_filename = f\"{name}-{counter}{ext}\"\n",
    "        apkg_output_path = os.path.join(anki_output_dir, apkg_filename)\n",
    "        counter += 1\n",
    "\n",
    "    print(f\"Packaging deck: {subject_name} for {person_name} to {apkg_output_path}\")\n",
    "\n",
    "    # Gather media files for this deck\n",
    "    media_files = []\n",
    "    for item in image_items:\n",
    "        original_filename = item[2]\n",
    "        processed_regions = item[4]  # List of (index, original_crop, processed_crop)\n",
    "\n",
    "        if processed_regions and processed_regions[0][0] is not None:\n",
    "            # For images with blue boxes, include all regions\n",
    "            for idx, orig_crop, proc_crop in processed_regions:\n",
    "                name, ext = os.path.splitext(original_filename)\n",
    "                region_suffix = f\"_region{idx+1}\"\n",
    "                \n",
    "                # Use the same filenames as saved in processed_images_output\n",
    "                processed_img_filename = f\"{name}{region_suffix}-1_processed{ext}\"\n",
    "                original_img_filename = f\"{name}{region_suffix}-1_original{ext}\"\n",
    "\n",
    "                # Get the full paths of the saved images\n",
    "                processed_img_path = os.path.join(\"./processed_images_output\", processed_img_filename)\n",
    "                original_img_path = os.path.join(\"./processed_images_output\", original_img_filename)\n",
    "\n",
    "                # Add the full paths to the media_files list\n",
    "                media_files.append(processed_img_path)\n",
    "                media_files.append(original_img_path)\n",
    "        else:\n",
    "            # For images without blue boxes\n",
    "            name, ext = os.path.splitext(original_filename)\n",
    "            processed_img_filename = f\"{name}-1_processed{ext}\"\n",
    "            original_img_filename = f\"{name}-1_original{ext}\"\n",
    "\n",
    "            # Get the full paths of the saved images\n",
    "            processed_img_path = os.path.join(\"./processed_images_output\", processed_img_filename)\n",
    "            original_img_path = os.path.join(\"./processed_images_output\", original_img_filename)\n",
    "\n",
    "            # Add the full paths to the media_files list\n",
    "            media_files.append(processed_img_path)\n",
    "            media_files.append(original_img_path)\n",
    "\n",
    "    # Create the Anki package with the media files\n",
    "    try:\n",
    "        genanki.Package(my_deck, media_files=media_files).write_to_file(apkg_output_path)\n",
    "        print(f\"Successfully created Anki package: {apkg_output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating Anki package: {e}\")\n",
    "\n",
    "print(\"All Anki packages created (with naming adjustments for existing files).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2GpcX6aMsnPV",
    "outputId": "d041cf65-32a3-4e4b-9acf-2dda14c8a0ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image deletion process completed.\n",
      "Deleted processed image: ./processed_images_output/image_pairs.csv\n",
      "Deleted directory: ./processed_images_output\n",
      "Processed images cleanup completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the base directory path\n",
    "base_dir = \".\"\n",
    "\n",
    "# Define the name of the directory to exclude from subject processing\n",
    "anki_cards_dir_name = \"완성된 안키 카드들\"\n",
    "\n",
    "# Traverse the base directory and its subdirectories\n",
    "for root, dirs, files in os.walk(base_dir, topdown=True):\n",
    "    # Exclude the anki_cards_dir_name from traversal\n",
    "    if anki_cards_dir_name in dirs:\n",
    "        dirs.remove(anki_cards_dir_name)\n",
    "\n",
    "    for file in files:\n",
    "        # Construct the full path to the file\n",
    "        file_path = os.path.join(root, file)\n",
    "\n",
    "        # Check if the file is a regular file and has an image extension\n",
    "        if os.path.isfile(file_path) and file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            try:\n",
    "                # Delete the image file\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted: {file_path}\")\n",
    "            except OSError as e:\n",
    "                print(f\"Error deleting file {file_path}: {e}\")\n",
    "\n",
    "print(\"Image deletion process completed.\")\n",
    "# Clean up processed_images_output directory\n",
    "processed_output_dir = \"./processed_images_output\"\n",
    "if os.path.exists(processed_output_dir):\n",
    "    try:\n",
    "        # Remove all files in the directory\n",
    "        for filename in os.listdir(processed_output_dir):\n",
    "            file_path = os.path.join(processed_output_dir, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted processed image: {file_path}\")\n",
    "        \n",
    "        # Remove the directory itself\n",
    "        os.rmdir(processed_output_dir)\n",
    "        print(f\"Deleted directory: {processed_output_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning up processed_images_output directory: {e}\")\n",
    "\n",
    "print(\"Processed images cleanup completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "py313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
